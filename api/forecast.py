import re
import requests
from bs4 import BeautifulSoup

def main(url):
    # è§£ææ¸ˆã¿ã®htmlãƒ‡ãƒ¼ã‚¿
    s = soup(url)
    # keyã¨valueæ ¼ç´ç”¨è¾æ›¸
    data = {}

    # è¾æ›¸ã«è¦ç´ è¿½åŠ 
    loc_cand_1 = r"(.+)ã®1æ™‚é–“å¤©æ°—"
    loc_cand_2 = s.title.text
    data['location'] = re.findall(loc_cand_1, loc_cand_2)[0]#ä¸€è‡´ã™ã‚‹ã‹ç¢ºèª
    print(data['location'] + "ã®å¤©æ°—")
    soup_today = s.find(id='forecast-point-1h-today')

    # æ—¥ä»˜å‡¦ç†
    d_date = r"(\d+)å¹´(\d+)æœˆ(\d+)æ—¥"
    d_src = s.select('.head p')
    date = re.findall(d_date, d_src[0].text)[0]
    data["date"] = "%så¹´%sæœˆ%sæ—¥" % (date[0], date[1], date[2])
    print("=====" + data["date"] + "=====\n")
    print(
        "æ™‚åˆ»      æ°—æ¸©(C)   å¤©æ°—"
    )

    # ä¸€æ™‚é–“ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹
    hour          = s.select('.hour > td')
    weather       = s.select('.weather > td')
    temperature   = s.select('.temperature > td')

    # æ ¼ç´
    data["forecasts"] = []
    for num in range(0, 24):
        forecast = {}
        forecast["hour"] = hour[num].text.strip()
        forecast["weather"] = weather[num].text.strip()
        forecast["temperature"] = temperature[num].text.strip()

        if forecast["weather"]=="å°é›¨":
            tenki = "ğŸŒ§  "
        elif forecast["weather"]=="æ™´ã‚Œ":
            tenki = "â˜€ï¸  "

        else:
            tenki = forecast["weather"]
        
        print("%-9s%-10s%s"%(forecast["hour"] + "æ™‚",  forecast["temperature"], tenki))

def soup(url):
    r = requests.get(url)
    html = r.text.encode(r.encoding)
    return BeautifulSoup(html, 'lxml')

if __name__ == '__main__':
    #ä¸­ç”ºã®ä¸€æ™‚é–“ã”ã¨ã®æ°—è±¡æƒ…å ±URL
    url = 'https://tenki.jp/forecast/3/16/4410/13210/1hour.html'
    main(url)